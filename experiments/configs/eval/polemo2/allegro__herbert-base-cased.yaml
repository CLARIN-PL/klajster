accelerator: auto
config: !!python/object:embeddings.config.lightning_config.LightningAdvancedConfig
  batch_encoding_kwargs: {}
  dataloader_kwargs: {}
  datamodule_kwargs:
    max_seq_length: null
  early_stopping_kwargs:
    mode: min
    monitor: val/Loss
    patience: 3
  finetune_last_n_layers: 3
  model_config_kwargs:
    classifier_dropout: 0.2
  task_model_kwargs:
    adam_epsilon: 1.0e-06
    eval_batch_size: 64
    learning_rate: 0.001
    optimizer: Adam
    train_batch_size: 64
    use_scheduler: true
    warmup_steps: 100
    weight_decay: 0.001
  task_train_kwargs:
    max_epochs: 3
  tokenizer_kwargs: {}
dataset_name_or_path: data/datasets/polemo2/lightning_hps/
devices: gpu
embedding_name_or_path: allegro/herbert-base-cased
input_column_name: text
load_dataset_kwargs: null
predict_subset: !!python/object/apply:embeddings.data.dataset.LightingDataModuleSubset
- test
target_column_name: target
tokenizer_name_or_path: allegro/herbert-base-cased
